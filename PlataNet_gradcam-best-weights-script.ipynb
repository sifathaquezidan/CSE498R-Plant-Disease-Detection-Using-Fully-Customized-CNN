{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13166744,"sourceType":"datasetVersion","datasetId":8343159},{"sourceId":13953911,"sourceType":"datasetVersion","datasetId":8894189}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Grad-CAM on BEST weights\n\nimport os, zipfile\nimport numpy as np\nfrom PIL import Image\nimport cv2\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, datasets\n\n\n# Paths / settings\nDATA_ROOT = \"/kaggle/input/plant-disease-dataset/Dataset_Final_V2_Split\"\nOUT_DIR   = \"/kaggle/working/plantanet_relu_final\"\nZIP_NAME  = \"gradcam_best.zip\"\n\nIMG_SIZE = 160\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# Preferred best-weights locations\nBEST_WEIGHTS_PATH = os.path.join(OUT_DIR, \"PlantaNet_ReLU_best_weights.pth\")\n\n# ACTUAL kaggle dataset path\nFALLBACK_BEST_1 = \"/kaggle/input/best-weights-dataset/PlantaNet_ReLU_best_weights.pth\"\n\n# extra fallbacks (only if needed)\nFALLBACK_BEST_2 = \"/kaggle/input/best-weights/PlantaNet_ReLU_best_weights.pth\"\nFALLBACK_FINAL  = \"/kaggle/input/final-weights/PlantaNet_ReLU_final_weights.pth\"\n\n\n# Transforms\neval_tfm = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\n\n# Dataset (test only)\ntest_dir = os.path.join(DATA_ROOT, \"test\")\ntest_ds  = datasets.ImageFolder(test_dir, transform=eval_tfm)\n\nclass_names = test_ds.classes\nNUM_CLASSES = len(class_names)\nprint(\"Classes:\", NUM_CLASSES, \"| Test:\", len(test_ds))\n\n\n# Model definition \nclass DepthwiseSeparableConv(nn.Module):\n    def __init__(self, in_ch, out_ch, stride=1):\n        super().__init__()\n        self.depth = nn.Conv2d(in_ch, in_ch, 3, stride, 1, groups=in_ch, bias=False)\n        self.point = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n        self.norm  = nn.GroupNorm(8 if out_ch % 8 == 0 else 4, out_ch)\n        self.act   = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        return self.act(self.norm(self.point(self.depth(x))))\n\nclass PlantaNetReLU(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        c1, c2, c3, c4 = 144, 224, 320, 448\n\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, c1, 3, 1, 1, bias=False),\n            nn.GroupNorm(8 if c1 % 8 == 0 else 4, c1),\n            nn.ReLU(inplace=True),\n        )\n        self.block1 = nn.Sequential(DepthwiseSeparableConv(c1, c2, stride=2), nn.Dropout(0.15))\n        self.block2 = nn.Sequential(DepthwiseSeparableConv(c2, c3, stride=2), nn.Dropout(0.20))\n        self.block3 = nn.Sequential(DepthwiseSeparableConv(c3, c4, stride=2), nn.Dropout(0.25))\n\n        self.conv_extra = nn.Sequential(\n            nn.Conv2d(c4, c4, 3, 1, 1, bias=False),\n            nn.GroupNorm(8 if c4 % 8 == 0 else 4, c4),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.25),\n        )\n\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(c4, 1024, bias=False),\n            nn.GroupNorm(8 if 1024 % 8 == 0 else 4, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.4),\n            nn.Linear(1024, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.conv_extra(x)\n        x = self.gap(x)\n        return self.classifier(x)\n\n\n# Load BEST weights safely\nmodel = PlantaNetReLU(NUM_CLASSES).to(DEVICE)\n\nweights_path = None\nfor p in [BEST_WEIGHTS_PATH, FALLBACK_BEST_1, FALLBACK_BEST_2, FALLBACK_FINAL]:\n    if os.path.exists(p):\n        weights_path = p\n        break\n\nif weights_path is None:\n    raise FileNotFoundError(\n        \"No weights found.\\n\"\n        f\"Tried:\\n- {BEST_WEIGHTS_PATH}\\n- {FALLBACK_BEST_1}\\n- {FALLBACK_BEST_2}\\n- {FALLBACK_FINAL}\"\n    )\n\nprint(\"Loading weights from:\", weights_path)\nstate = torch.load(weights_path, map_location=DEVICE)\n\n# handle DataParallel keys if needed\nif any(k.startswith(\"module.\") for k in state.keys()):\n    state = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n\nmodel.load_state_dict(state, strict=False)\nmodel.eval()\n\n\n# Grad-CAM implementation\ntarget_layer = model.conv_extra[0]\n\nclass GradCAM:\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n        self.gradients = None\n        self.activations = None\n\n        target_layer.register_forward_hook(self._save_activation)\n        target_layer.register_full_backward_hook(self._save_gradient)\n\n    def _save_activation(self, module, inp, out):\n        self.activations = out.detach()\n\n    def _save_gradient(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0].detach()\n\n    def generate(self, input_tensor, class_idx=None):\n        self.model.zero_grad()\n        outputs = self.model(input_tensor)\n        if class_idx is None:\n            class_idx = int(outputs.argmax(dim=1).item())\n\n        score = outputs[:, class_idx]\n        score.backward(retain_graph=False)\n\n        grads = self.gradients\n        acts  = self.activations\n\n        weights = grads.mean(dim=(2, 3), keepdim=True)  # GAP on gradients\n        cam = (weights * acts).sum(dim=1).squeeze(0)\n        cam = torch.relu(cam)\n\n        cam_np = cam.cpu().numpy()\n        cam_np -= cam_np.min()\n        cam_np /= (cam_np.max() + 1e-9)\n        return cam_np\n\ngradcam = GradCAM(model, target_layer)\n\n# denorm helper\nmean = np.array([0.485, 0.456, 0.406]).reshape(3,1,1)\nstd  = np.array([0.229, 0.224, 0.225]).reshape(3,1,1)\n\ndef denorm_tensor(img_tensor):\n    arr = img_tensor.cpu().numpy()\n    arr = (arr * std) + mean\n    arr = np.clip(arr, 0, 1)\n    return np.transpose(arr, (1,2,0))\n\n\n# Pick one correct sample per class\nprint(\"Collecting correct samples...\")\ncorrect_samples = {cls: [] for cls in range(NUM_CLASSES)}\n\nwith torch.no_grad():\n    for path, label in test_ds.samples:\n        img = Image.open(path).convert(\"RGB\")\n        tensor = eval_tfm(img).unsqueeze(0).to(DEVICE)\n        out = model(tensor)\n        pred = out.argmax(1).item()\n        if pred == label:\n            correct_samples[label].append(path)\n\n\n# Generate and save Grad-CAM\ngradcam_dir = os.path.join(OUT_DIR, \"gradcam_best\")\nos.makedirs(gradcam_dir, exist_ok=True)\n\nprint(\"Generating Grad-CAM...\")\nfor cls in range(NUM_CLASSES):\n    if len(correct_samples[cls]) == 0:\n        print(f\"No correct sample for {class_names[cls]}\")\n        continue\n\n    path = correct_samples[cls][0]\n    pil = Image.open(path).convert(\"RGB\")\n    tensor = eval_tfm(pil).unsqueeze(0).to(DEVICE)\n\n    cam_map = gradcam.generate(tensor, class_idx=cls)\n    cam_resized = cv2.resize(cam_map, (IMG_SIZE, IMG_SIZE))\n\n    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)[:, :, ::-1]\n\n    original = denorm_tensor(tensor[0])\n    orig_uint8 = np.uint8(original * 255)\n    heat_uint8 = np.uint8(heatmap)\n\n    overlay = cv2.addWeighted(orig_uint8, 0.6, heat_uint8, 0.4, 0)\n\n    cls_name = class_names[cls].replace(\"/\", \"_\").replace(\" \", \"_\")\n    cls_folder = os.path.join(gradcam_dir, cls_name)\n    os.makedirs(cls_folder, exist_ok=True)\n\n    save_path = os.path.join(cls_folder, f\"gradcam_{cls_name}.png\")\n    cv2.imwrite(save_path, overlay[:, :, ::-1])\n    print(\"Saved:\", cls_name)\n\nprint(\"Done. Saved under:\", gradcam_dir)\n\n\n# Auto-zip for download\nzip_path = os.path.join(OUT_DIR, ZIP_NAME)\nprint(\"Zipping to:\", zip_path)\n\nwith zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n    for root, _, files in os.walk(gradcam_dir):\n        for f in files:\n            full_path = os.path.join(root, f)\n            rel_path = os.path.relpath(full_path, gradcam_dir)\n            zf.write(full_path, arcname=os.path.join(\"gradcam_best\", rel_path))\n\nprint(\"Zip ready:\", zip_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T06:04:55.779855Z","iopub.execute_input":"2025-12-02T06:04:55.780142Z","iopub.status.idle":"2025-12-02T06:16:15.937079Z","shell.execute_reply.started":"2025-12-02T06:04:55.780123Z","shell.execute_reply":"2025-12-02T06:16:15.936116Z"}},"outputs":[{"name":"stdout","text":"Device: cpu\nClasses: 51 | Test: 20506\nLoading weights from: /kaggle/input/best-weights-dataset/PlantaNet_ReLU_best_weights.pth\nCollecting correct samples...\nGenerating Grad-CAM...\nSaved: Apple___Apple_scab\nSaved: Apple___Black_rot\nSaved: Apple___Cedar_apple_rust\nSaved: Apple___healthy\nSaved: Banana___cordana\nSaved: Banana___healthy\nSaved: Banana___pestalotiopsis\nSaved: Banana___sigatoka\nSaved: Bean___angular_leaf_spot\nSaved: Bean___bean_rust\nSaved: Bean___healthy\nSaved: Blueberry___healthy\nSaved: Corn___Cercospora_leaf_spot_Gray_leaf_spot\nSaved: Corn___Common_rust_\nSaved: Corn___Northern_Leaf_Blight\nSaved: Corn___healthy\nSaved: Grape___Black_rot\nSaved: Grape___Esca_(Black_Measles)\nSaved: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\nSaved: Grape___healthy\nSaved: Mango___Anthracnose\nSaved: Mango___Bacterial_Canker\nSaved: Mango___Cutting_Weevil\nSaved: Mango___Die_Back\nSaved: Mango___Gall_Midge\nSaved: Mango___Healthy\nSaved: Mango___Powdery_Mildew\nSaved: Mango___Sooty_Mould\nSaved: Pepper,_bell___Bacterial_spot\nSaved: Pepper,_bell___healthy\nSaved: Potato___Early_blight\nSaved: Potato___Late_blight\nSaved: Potato___healthy\nSaved: Rice___bacterial_leaf_blight\nSaved: Rice___brown_spot\nSaved: Rice___healthy\nSaved: Rice___leaf_blast\nSaved: Rice___leaf_scald\nSaved: Rice___narrow_brown_spot\nSaved: Strawberry___Leaf_scorch\nSaved: Strawberry___healthy\nSaved: Tomato___Bacterial_spot\nSaved: Tomato___Early_blight\nSaved: Tomato___Late_blight\nSaved: Tomato___Leaf_Mold\nSaved: Tomato___Septoria_leaf_spot\nSaved: Tomato___Spider_mites_Two-spotted_spider_mite\nSaved: Tomato___Target_Spot\nSaved: Tomato___Tomato_Yellow_Leaf_Curl_Virus\nSaved: Tomato___Tomato_mosaic_virus\nSaved: Tomato___healthy\nDone. Saved under: /kaggle/working/plantanet_relu_final/gradcam_best\nZipping to: /kaggle/working/plantanet_relu_final/gradcam_best.zip\nZip ready: /kaggle/working/plantanet_relu_final/gradcam_best.zip\n","output_type":"stream"}],"execution_count":2}]}